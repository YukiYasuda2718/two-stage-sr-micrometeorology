{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd8965a-9cc7-4cc6-af21-4325a8f8910f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb21d6b-b315-43e2-a77d-71cba1fc6f54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from logging import INFO, WARNING, StreamHandler, getLogger\n",
    "\n",
    "logger = getLogger()\n",
    "if not logger.hasHandlers():\n",
    "    logger.addHandler(StreamHandler(sys.stdout))\n",
    "logger.setLevel(INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3933cbe6-d440-4863-86ee-37227c251977",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8a61e2-3ce3-4f4f-a2e4-31203b514222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "import pathlib\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import yaml\n",
    "from src.data.dataloader import make_dataloaders_and_samplers\n",
    "from src.models.evaluation_helper import (\n",
    "    AveSsimLoss,\n",
    "    TemperatureErrorNorm,\n",
    "    VelocityComponentErrorNorm,\n",
    "    VelocityErrorNorm,\n",
    "    evaluate,\n",
    ")\n",
    "from src.models.model_maker import make_model\n",
    "from src.utils.io_pickle import read_pickle\n",
    "from src.utils.random_seed_helper import set_seeds\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"serif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a33ca3-cee5-413d-8f6f-533a5fa4b1c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_seeds(42)\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = r\":4096:8\"  # to make calculations deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acb4d39-4af6-4410-abf2-0dce2be9c662",
   "metadata": {},
   "source": [
    "# Define constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56640ab8-64ca-4e1b-9ba5-78406a1785ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = str((pathlib.Path(os.environ[\"PYTHONPATH\"]) / \"..\").resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e29b4ab-af59-48cf-b192-5cafc626bce8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83a885d-0602-404e-a440-2b955b11f692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TMP_DATA_DIR = \"./tmp\"\n",
    "os.makedirs(TMP_DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81f5d57-6d26-4f32-b2d3-cf08189722a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"lr-inference\"\n",
    "CONFIG_DIR = f\"{ROOT_DIR}/python/configs/{EXPERIMENT_NAME}\"\n",
    "CONFIG_PATHS = sorted([p for p in glob.glob(f\"{CONFIG_DIR}/*.yml\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61a54ccd-7d34-4d4c-828d-504d808c2f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIGS = OrderedDict()\n",
    "\n",
    "for config_path in CONFIG_PATHS:\n",
    "    if \"test\" in os.path.basename(config_path):\n",
    "        continue\n",
    "\n",
    "    with open(config_path) as file:\n",
    "        config = yaml.safe_load(file)\n",
    "\n",
    "    config_name = os.path.basename(config_path).split(\".\")[0]\n",
    "    assert config_name not in CONFIGS\n",
    "\n",
    "    experiment_name = config_path.split(\"/\")[-2]\n",
    "    _dir = f\"{ROOT_DIR}/data/models/{experiment_name}/{config_name}\"\n",
    "\n",
    "    CONFIGS[config_name] = {\n",
    "        \"config\": config,\n",
    "        \"experiment_name\": experiment_name,\n",
    "        \"weight_path\": f\"{_dir}/model_weight.pth\",\n",
    "        \"learning_history_path\": f\"{_dir}/model_loss_history.csv\",\n",
    "        \"log_path\": f\"{_dir}/log.txt\",\n",
    "        \"test_score_path\": f\"{_dir}/test_errors.pickle\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ee6f4-cdb0-4094-919c-cc7ea5240abf",
   "metadata": {},
   "source": [
    "# Define methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0188e27-f472-4700-8041-af759f31fe51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dict_loss_fns(config: dict):\n",
    "    return {\n",
    "        \"T-ErrorNorm[K]\": TemperatureErrorNorm(scale=config[\"data\"][\"scales\"][0]),\n",
    "        \"u-ErrorNorm[m/s]\": VelocityComponentErrorNorm(\n",
    "            scale=config[\"data\"][\"scales\"][1], idx_channel=1\n",
    "        ),\n",
    "        \"v-ErrorNorm[m/s]\": VelocityComponentErrorNorm(\n",
    "            scale=config[\"data\"][\"scales\"][2], idx_channel=2\n",
    "        ),\n",
    "        \"w-ErrorNorm[m/s]\": VelocityComponentErrorNorm(\n",
    "            scale=config[\"data\"][\"scales\"][3], idx_channel=3\n",
    "        ),\n",
    "        \"VelocityErrorNorm\": VelocityErrorNorm(\n",
    "            scales=config[\"data\"][\"scales\"][1:], device=DEVICE\n",
    "        ),\n",
    "        \"AveSsimLoss\": AveSsimLoss(),\n",
    "    }\n",
    "\n",
    "\n",
    "def aggregate_err_by_time(timestamps: list, all_errors: dict):\n",
    "    grouped_errors = {}\n",
    "\n",
    "    for k, errors in all_errors.items():\n",
    "        grouped_errors[k] = {m: [] for m in range(11, 61, 1)}\n",
    "        assert len(errors.shape) == 2  # time and height dims\n",
    "        assert errors.shape[0] == len(timestamps)  # time dim\n",
    "        assert errors.shape[1] == 10  # height dim\n",
    "\n",
    "        for i, dt in enumerate(timestamps):\n",
    "            minutes = int(dt.minute)\n",
    "            if minutes == 0:\n",
    "                minutes = 60\n",
    "\n",
    "            grouped_errors[k][minutes].append(errors[i])\n",
    "\n",
    "        for minutes in grouped_errors[k].keys():\n",
    "            vals = grouped_errors[k][minutes]\n",
    "            if len(vals) > 0:\n",
    "                grouped_errors[k][minutes] = np.stack(vals)\n",
    "            else:\n",
    "                grouped_errors[k][minutes] = np.nan\n",
    "\n",
    "    return grouped_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bad8de3-93b1-475e-8022-3f2215ad1784",
   "metadata": {},
   "source": [
    "# Plot learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a77fb74-8fdf-4378-b531-0738bcd3041d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_plotted = True\n",
    "\n",
    "for config_name, config_info in CONFIGS.items():\n",
    "    config_info[\"is_not_ended\"] = True\n",
    "    config = config_info[\"config\"]\n",
    "\n",
    "    if not os.path.exists(config_info[\"log_path\"]):\n",
    "        logger.info(f\"Log does not exist: {config_name}\")\n",
    "        continue\n",
    "\n",
    "    with open(config_info[\"log_path\"], \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "    if not lines[-3].startswith(\"End DDP:\"):\n",
    "        logger.warning(f\"Training is not finished: {config_name}\")\n",
    "\n",
    "    df = pd.read_csv(config_info[\"learning_history_path\"])\n",
    "    assert len(df) < config[\"train\"][\"epochs\"]\n",
    "\n",
    "    config_info[\"is_not_ended\"] = False\n",
    "\n",
    "    if not is_plotted:\n",
    "        continue\n",
    "\n",
    "    plt.rcParams[\"font.size\"] = 15\n",
    "    fig = plt.figure(figsize=[5, 3])\n",
    "    ax = plt.subplot(111)\n",
    "\n",
    "    df.plot(\n",
    "        ax=ax,\n",
    "        xlabel=\"Epochs\",\n",
    "        ylabel=\"Loss\",\n",
    "    )\n",
    "    ax.set_title(f'{config_name}\\n{config[\"loss\"][\"name\"]}')\n",
    "    ax.set_yscale(\"log\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # fig.savefig(f\"{FIG_DIR}/learning_curve_{config_name}.webp\", bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17dcb1ab-6c07-431f-9ce6-a9e85580351d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dff8385-8954-4274-b6ec-e52fbf70917d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dict_results = {}\n",
    "\n",
    "for config_name, config_info in tqdm(CONFIGS.items(), total=len(CONFIGS)):\n",
    "    #\n",
    "    if \"test\" in config_name:\n",
    "        continue\n",
    "\n",
    "    if config_info[\"is_not_ended\"]:\n",
    "        logger.info(f\"Training is not finished. {config_name}\")\n",
    "        continue\n",
    "    else:\n",
    "        logger.info(f\"\\n{config_name} is being evaluated.\")\n",
    "\n",
    "    config = copy.deepcopy(config_info[\"config\"])\n",
    "    config[\"data\"][\"batch_size\"] = 1  # This must be 1 to easily obtain timestamps.\n",
    "    assert \"use_clipping_ground_truth\" in config[\"data\"]\n",
    "    config[\"data\"][\"use_clipping_ground_truth\"] = False\n",
    "\n",
    "    logger.setLevel(WARNING)\n",
    "    dataloaders, _ = make_dataloaders_and_samplers(\n",
    "        root_dir=ROOT_DIR, config=config[\"data\"], train_valid_test_kinds=[\"test\"]\n",
    "    )\n",
    "\n",
    "    model = make_model(config[\"model\"]).to(DEVICE)\n",
    "    model.load_state_dict(torch.load(config_info[\"weight_path\"], map_location=DEVICE))\n",
    "    _ = model.eval()\n",
    "    logger.setLevel(INFO)\n",
    "\n",
    "    loss_fns = get_dict_loss_fns(config)\n",
    "\n",
    "    test_errors = evaluate(\n",
    "        dataloader=dataloaders[\"test\"], model=model, loss_fns=loss_fns, device=DEVICE\n",
    "    )\n",
    "\n",
    "    idx = 1 if dataloaders[\"test\"].dataset.n_input_snapshots == 3 else 0\n",
    "    logger.info(\n",
    "        f\"n_input = {dataloaders['test'].dataset.n_input_snapshots}, so idx = {idx}\"\n",
    "    )\n",
    "\n",
    "    # e.g., lr_tokyo_05m_20130709T040100.npy --> 20130709T040100\n",
    "    timestamps = [\n",
    "        datetime.datetime.strptime(\n",
    "            os.path.basename(ps[idx]).split(\"_\")[-1].replace(\".npy\", \"\"),\n",
    "            \"%Y%m%dT%H%M%S\",\n",
    "        )\n",
    "        for ps in dataloaders[\"test\"].dataset.truth_all_file_paths\n",
    "    ]\n",
    "\n",
    "    dict_results[config_name] = {\n",
    "        \"timestamps\": timestamps,\n",
    "        \"errors\": test_errors,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1b543a-0e3c-4e43-826f-69724064b320",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot snapshots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d992880-a633-4f76-a824-96dac96dbec1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_name = \"default_lr\"\n",
    "max_idx = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d083067-2e16-48c1-99d3-094fc8b3a07d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config_info = CONFIGS[config_name]\n",
    "config = copy.deepcopy(config_info[\"config\"])\n",
    "assert \"use_clipping_ground_truth\" in config[\"data\"]\n",
    "config[\"data\"][\"use_clipping_ground_truth\"] = False\n",
    "\n",
    "logger.setLevel(WARNING)\n",
    "dataloaders, _ = make_dataloaders_and_samplers(\n",
    "    root_dir=ROOT_DIR, config=config[\"data\"], train_valid_test_kinds=[\"test\"]\n",
    ")\n",
    "\n",
    "model = make_model(config[\"model\"]).to(DEVICE)\n",
    "model.load_state_dict(torch.load(config_info[\"weight_path\"], map_location=DEVICE))\n",
    "_ = model.eval()\n",
    "logger.setLevel(INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb423a24-5918-40b7-bf7a-53f3610baf1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ts, Xs, bs, gt, timestamps = [], [], [], [], []\n",
    "for i in range(max_idx):\n",
    "    t, X, b, g, path = dataloaders[\"test\"].dataset.__getitem__(\n",
    "        idx=i, return_hr_path=True\n",
    "    )\n",
    "    ts.append(t)\n",
    "    Xs.append(X)\n",
    "    bs.append(b)\n",
    "    gt.append(g)\n",
    "    timestamps.append(os.path.basename(path).split(\"_\")[-1].replace(\".npy\", \"\"))\n",
    "\n",
    "ts = torch.stack(ts)\n",
    "Xs = torch.stack(Xs)\n",
    "bs = torch.stack(bs)\n",
    "gt = torch.stack(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7066ba04-d17c-4038-a89f-b31fc7fe2309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preds = model(t=ts.to(DEVICE), x=Xs.to(DEVICE), b=bs.to(DEVICE)).detach().cpu()\n",
    "assert Xs.shape[1:] == (4, 10, 80, 80)  # channel, z, y, x\n",
    "\n",
    "Xs = dataloaders[\"test\"].dataset._scale_inversely(Xs)\n",
    "gt = dataloaders[\"test\"].dataset._scale_inversely(gt)\n",
    "preds = dataloaders[\"test\"].dataset._scale_inversely(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19c23c3-e6bf-4564-be03-6b80d3f609b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i_batch in range(max_idx):\n",
    "    lr_bldg = bs[i_batch]\n",
    "    hr_dataset = gt[i_batch]\n",
    "    lr_dataset = Xs[i_batch]\n",
    "    sr_dataset = preds[i_batch]\n",
    "    figsize = [24, 6]\n",
    "\n",
    "    dict_cmap = {\n",
    "        \"tm\": \"turbo\",\n",
    "        \"vl\": \"YlOrRd\",\n",
    "        \"vp\": \"YlGnBu\",\n",
    "        \"vr\": \"viridis\",\n",
    "    }\n",
    "\n",
    "    sx, ex = 0, None\n",
    "    sy, ey = 0, None\n",
    "\n",
    "    for ilev in [0, 4]:\n",
    "        plt.rcParams[\"font.size\"] = 14\n",
    "        fig, axes = plt.subplots(2, 6, figsize=figsize)\n",
    "        axes = np.ravel(axes)\n",
    "\n",
    "        is_out_bldg = lr_bldg[0, ilev].numpy().transpose()[sx:ex, sy:ey]\n",
    "        height = 20.0 * ilev + 10.0\n",
    "\n",
    "        for i, (v, cmap) in enumerate(dict_cmap.items()):\n",
    "            vmin, vmax = None, None\n",
    "\n",
    "            hr_gt = None\n",
    "            for ax, resolution, org_data in zip(\n",
    "                [axes[3 * i], axes[3 * i + 1], axes[3 * i + 2]],\n",
    "                [\"HR(resized)\", \"LR\", \"SR\"],\n",
    "                [hr_dataset[i, ilev], lr_dataset[i, ilev], sr_dataset[i, ilev]],\n",
    "            ):\n",
    "                assert org_data.ndim == 2  # y and x dims\n",
    "\n",
    "                ax.set_aspect(\"equal\")\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                data = org_data.clone().numpy().transpose()[sx:ex, sy:ey]\n",
    "                assert data.shape[0] == data.shape[1], \"Not equal aspect ratio\"\n",
    "\n",
    "                data = np.where(is_out_bldg, data, np.nan)\n",
    "\n",
    "                if v == \"tm\":\n",
    "                    data -= 273.15\n",
    "\n",
    "                dx = 20\n",
    "                xs = np.arange(data.shape[0]) * dx\n",
    "                ys = np.arange(data.shape[1]) * dx\n",
    "\n",
    "                xs, ys = np.meshgrid(xs, ys, indexing=\"ij\")\n",
    "\n",
    "                if resolution == \"HR(resized)\":\n",
    "                    vmin = np.nanquantile(data.flatten(), 0.02)\n",
    "                    vmax = np.nanquantile(data.flatten(), 0.98)\n",
    "                    hr_gt = data\n",
    "                    print(f\"{v}, {vmin:.1f}, {vmax:.1f}\")\n",
    "                    ax.set_title(f\"{resolution}: {v}\\nz = {height:.1f} m\")\n",
    "                else:\n",
    "                    abs_diff = np.abs(data - hr_gt)\n",
    "                    mae = np.nanmean(abs_diff)\n",
    "                    ax.set_title(f\"{resolution}: {v}\\nMAE = {mae:.3f}\")\n",
    "\n",
    "                my_cmap = copy.deepcopy(matplotlib.colormaps[dict_cmap[v]])\n",
    "                my_cmap.set_bad(\"dimgray\")\n",
    "\n",
    "                contours = ax.pcolormesh(\n",
    "                    xs, ys, data, vmin=vmin, vmax=vmax, cmap=my_cmap\n",
    "                )\n",
    "                fig.colorbar(contours, ax=ax, extend=\"both\")\n",
    "\n",
    "        plt.suptitle(f\"{timestamps[i_batch]}, z = {height:03} m\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e08cc1c7-5fe2-4aa3-974d-e49515a477b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
